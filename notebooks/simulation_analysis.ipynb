{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Systems Simulator\n",
    "## Portfolio Risk Analysis with Monte Carlo Simulation\n",
    "\n",
    "This notebook demonstrates the **QSS** - a hybrid Python/C++ system for quantitative portfolio analysis.\n",
    "\n",
    "### System Architecture\n",
    "```\n",
    "User Input (Portfolio / Dataset)\n",
    "        |\n",
    "        v\n",
    "Python Ingestion Layer (pandas, data cleaning)\n",
    "        |\n",
    "        v\n",
    "+---> C++ Simulation Core (Monte Carlo Engine) <---+\n",
    "|     - Multi-threaded parallel execution          |\n",
    "|     - Cholesky decomposition                     |\n",
    "|     - Variance reduction techniques              |\n",
    "+--------------------------------------------------+\n",
    "        |\n",
    "        v\n",
    "Statistical Analysis (Python + NumPy/SciPy)\n",
    "        |\n",
    "        v\n",
    "Visualization Dashboard (Matplotlib / Plotly)\n",
    "        |\n",
    "        v\n",
    "JSON + Report Outputs\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../python')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from qss import Orchestrator, PortfolioAnalytics, Visualizer\n",
    "from qss.interface import SimulationConfig, AssetData, HAS_CPP_CORE\n",
    "\n",
    "# Check if C++ core is available\n",
    "print(f\"C++ Core Available: {HAS_CPP_CORE}\")\n",
    "if HAS_CPP_CORE:\n",
    "    print(\"Using high-performance C++ Monte Carlo engine\")\n",
    "else:\n",
    "    print(\"Using Python fallback (NumPy-based)\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Portfolio Construction\n",
    "\n",
    "We'll create a **Tech Growth Portfolio** with 5 major assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define portfolio assets\n",
    "portfolio_data = {\n",
    "    'Symbol': ['AAPL', 'MSFT', 'NVDA', 'GOOG', 'AMZN'],\n",
    "    'Name': ['Apple', 'Microsoft', 'NVIDIA', 'Alphabet', 'Amazon'],\n",
    "    'Weight': [0.25, 0.25, 0.20, 0.15, 0.15],\n",
    "    'Expected Return': [0.12, 0.10, 0.18, 0.11, 0.14],\n",
    "    'Volatility': [0.25, 0.22, 0.40, 0.28, 0.32]\n",
    "}\n",
    "\n",
    "portfolio_df = pd.DataFrame(portfolio_data)\n",
    "portfolio_df['Weight %'] = portfolio_df['Weight'].apply(lambda x: f\"{x:.0%}\")\n",
    "portfolio_df['Expected Return %'] = portfolio_df['Expected Return'].apply(lambda x: f\"{x:.1%}\")\n",
    "portfolio_df['Volatility %'] = portfolio_df['Volatility'].apply(lambda x: f\"{x:.1%}\")\n",
    "\n",
    "display(portfolio_df[['Symbol', 'Name', 'Weight %', 'Expected Return %', 'Volatility %']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize portfolio allocation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart for weights\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(portfolio_df)))\n",
    "axes[0].pie(portfolio_df['Weight'], labels=portfolio_df['Symbol'], autopct='%1.0f%%',\n",
    "            colors=colors, explode=[0.02]*5)\n",
    "axes[0].set_title('Portfolio Allocation', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart for risk/return\n",
    "x = np.arange(len(portfolio_df))\n",
    "width = 0.35\n",
    "bars1 = axes[1].bar(x - width/2, portfolio_df['Expected Return']*100, width, \n",
    "                    label='Expected Return', color='steelblue')\n",
    "bars2 = axes[1].bar(x + width/2, portfolio_df['Volatility']*100, width,\n",
    "                    label='Volatility', color='coral')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(portfolio_df['Symbol'])\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Risk-Return Profile by Asset', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix\n",
    "\n",
    "Asset correlations are crucial for portfolio risk. We define a realistic correlation structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define correlation matrix\n",
    "correlation = np.array([\n",
    "    [1.00, 0.65, 0.55, 0.60, 0.58],  # AAPL\n",
    "    [0.65, 1.00, 0.52, 0.58, 0.55],  # MSFT\n",
    "    [0.55, 0.52, 1.00, 0.48, 0.52],  # NVDA\n",
    "    [0.60, 0.58, 0.48, 1.00, 0.62],  # GOOG\n",
    "    [0.58, 0.55, 0.52, 0.62, 1.00]   # AMZN\n",
    "])\n",
    "\n",
    "# Compute covariance matrix\n",
    "vols = portfolio_df['Volatility'].values\n",
    "cov_matrix = np.outer(vols, vols) * correlation\n",
    "\n",
    "# Plot correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            xticklabels=portfolio_df['Symbol'], yticklabels=portfolio_df['Symbol'],\n",
    "            square=True, linewidths=0.5, ax=ax)\n",
    "ax.set_title('Asset Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Monte Carlo Simulation\n",
    "\n",
    "We'll run **10,000 simulations** over a 1-year horizon (252 trading days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = SimulationConfig(\n",
    "    n_simulations=10000,\n",
    "    time_horizon=252,  # Trading days in a year\n",
    "    risk_free_rate=0.02,  # 2% risk-free rate\n",
    "    seed=42  # For reproducibility\n",
    ")\n",
    "\n",
    "print(\"Simulation Configuration:\")\n",
    "print(f\"  Number of Simulations: {config.n_simulations:,}\")\n",
    "print(f\"  Time Horizon: {config.time_horizon} trading days (1 year)\")\n",
    "print(f\"  Risk-Free Rate: {config.risk_free_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize orchestrator and load portfolio\n",
    "orch = Orchestrator(config)\n",
    "\n",
    "# Load portfolio from dictionary\n",
    "portfolio_dict = {\n",
    "    \"assets\": [\n",
    "        {\"symbol\": row['Symbol'], \"weight\": row['Weight'],\n",
    "         \"expected_return\": row['Expected Return'], \"volatility\": row['Volatility']}\n",
    "        for _, row in portfolio_df.iterrows()\n",
    "    ]\n",
    "}\n",
    "orch.load_portfolio_from_dict(portfolio_dict, cov_matrix)\n",
    "\n",
    "# Run simulation\n",
    "print(\"Running Monte Carlo simulation...\")\n",
    "result = orch.run_simulation()\n",
    "print(f\"Generated {len(result.terminal_values):,} scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Risk Metrics Analysis\n",
    "\n",
    "Key metrics for portfolio risk assessment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = result.metrics\n",
    "\n",
    "# Create metrics summary\n",
    "metrics_data = {\n",
    "    'Metric': [\n",
    "        'Expected Annual Return',\n",
    "        'Volatility (Std Dev)',\n",
    "        'Sharpe Ratio',\n",
    "        'Value at Risk (95%)',\n",
    "        'Value at Risk (99%)',\n",
    "        'Conditional VaR (95%)',\n",
    "        'Conditional VaR (99%)',\n",
    "        'Skewness',\n",
    "        'Excess Kurtosis',\n",
    "        'Avg Max Drawdown'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{metrics.expected_return:.2%}\",\n",
    "        f\"{metrics.volatility:.2%}\",\n",
    "        f\"{metrics.sharpe_ratio:.2f}\",\n",
    "        f\"{metrics.var_95:.2%}\",\n",
    "        f\"{metrics.var_99:.2%}\",\n",
    "        f\"{metrics.cvar_95:.2%}\",\n",
    "        f\"{metrics.cvar_99:.2%}\",\n",
    "        f\"{metrics.skewness:.3f}\",\n",
    "        f\"{metrics.kurtosis:.3f}\",\n",
    "        f\"{metrics.max_drawdown:.2%}\"\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Mean simulated return over 1 year',\n",
    "        'Standard deviation of returns',\n",
    "        '(Return - Rf) / Volatility',\n",
    "        '95% confidence worst-case loss',\n",
    "        '99% confidence worst-case loss',\n",
    "        'Expected loss beyond VaR (95%)',\n",
    "        'Expected loss beyond VaR (99%)',\n",
    "        'Asymmetry of return distribution',\n",
    "        'Fat tails (>0 = heavier than normal)',\n",
    "        'Average peak-to-trough decline'\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = result.terminal_values - 1.0  # Convert to returns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram with VaR lines\n",
    "ax1 = axes[0]\n",
    "n, bins, patches = ax1.hist(returns, bins=80, density=True, alpha=0.7, \n",
    "                             color='steelblue', edgecolor='white')\n",
    "\n",
    "# Add KDE\n",
    "from scipy import stats\n",
    "kde_x = np.linspace(returns.min(), returns.max(), 200)\n",
    "kde = stats.gaussian_kde(returns)\n",
    "ax1.plot(kde_x, kde(kde_x), 'darkblue', linewidth=2, label='KDE')\n",
    "\n",
    "# VaR and CVaR lines\n",
    "ax1.axvline(metrics.var_95, color='orange', linestyle='--', linewidth=2, \n",
    "            label=f'VaR 95%: {metrics.var_95:.1%}')\n",
    "ax1.axvline(metrics.cvar_95, color='red', linestyle=':', linewidth=2,\n",
    "            label=f'CVaR 95%: {metrics.cvar_95:.1%}')\n",
    "ax1.axvline(np.mean(returns), color='green', linestyle='-', linewidth=2,\n",
    "            label=f'Mean: {np.mean(returns):.1%}')\n",
    "\n",
    "ax1.set_xlabel('Annual Return', fontsize=12)\n",
    "ax1.set_ylabel('Density', fontsize=12)\n",
    "ax1.set_title('Portfolio Return Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "\n",
    "# Q-Q plot for normality check\n",
    "ax2 = axes[1]\n",
    "stats.probplot(returns, dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('Q-Q Plot (Normality Check)', fontsize=14, fontweight='bold')\n",
    "ax2.get_lines()[0].set_markerfacecolor('steelblue')\n",
    "ax2.get_lines()[0].set_alpha(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Simulation Paths Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = result.simulated_paths\n",
    "n_steps = paths.shape[1]\n",
    "time_axis = np.arange(n_steps)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot sample paths\n",
    "n_sample = 100\n",
    "sample_idx = np.random.choice(len(paths), n_sample, replace=False)\n",
    "for idx in sample_idx:\n",
    "    ax.plot(time_axis, paths[idx], alpha=0.1, color='steelblue', linewidth=0.5)\n",
    "\n",
    "# Percentile bands\n",
    "p5 = np.percentile(paths, 5, axis=0)\n",
    "p25 = np.percentile(paths, 25, axis=0)\n",
    "p50 = np.percentile(paths, 50, axis=0)\n",
    "p75 = np.percentile(paths, 75, axis=0)\n",
    "p95 = np.percentile(paths, 95, axis=0)\n",
    "\n",
    "ax.fill_between(time_axis, p5, p95, alpha=0.2, color='steelblue', label='5-95%')\n",
    "ax.fill_between(time_axis, p25, p75, alpha=0.3, color='steelblue', label='25-75%')\n",
    "ax.plot(time_axis, p50, color='darkblue', linewidth=2, label='Median')\n",
    "\n",
    "ax.axhline(1.0, color='gray', linestyle='--', alpha=0.5, label='Initial Value')\n",
    "\n",
    "ax.set_xlabel('Trading Days', fontsize=12)\n",
    "ax.set_ylabel('Portfolio Value', fontsize=12)\n",
    "ax.set_title(f'Monte Carlo Simulation Paths ({config.n_simulations:,} scenarios)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlim(0, n_steps-1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute extended analytics\n",
    "analytics = orch.compute_analytics()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTICAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Distribution analysis\n",
    "dist = analytics['distribution_analysis']\n",
    "print(\"\\nDistribution Properties:\")\n",
    "print(f\"  Skewness: {dist['moments']['skewness']:.3f}\")\n",
    "print(f\"  Excess Kurtosis: {dist['moments']['kurtosis']:.3f}\")\n",
    "print(f\"  Is Fat-Tailed: {dist['is_fat_tailed']}\")\n",
    "print(f\"  Is Skewed: {dist['is_skewed']}\")\n",
    "\n",
    "# Normality tests\n",
    "print(\"\\nNormality Tests:\")\n",
    "jb = dist['normality_tests']['jarque_bera']\n",
    "sw = dist['normality_tests']['shapiro_wilk']\n",
    "print(f\"  Jarque-Bera: statistic={jb['statistic']:.2f}, p-value={jb['p_value']:.4f}\")\n",
    "print(f\"  Shapiro-Wilk: statistic={sw['statistic']:.4f}, p-value={sw['p_value']:.4f}\")\n",
    "print(f\"  Conclusion: {'Normal' if jb['is_normal'] else 'Non-Normal'} distribution\")\n",
    "\n",
    "# Confidence intervals\n",
    "print(\"\\n95% Confidence Intervals:\")\n",
    "cis = analytics['confidence_intervals']\n",
    "for name, ci in cis.items():\n",
    "    print(f\"  {name}: [{ci['lower']:.4f}, {ci['upper']:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. VaR Analysis at Multiple Confidence Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VaR at multiple levels\n",
    "confidence_levels = [0.90, 0.95, 0.99, 0.999]\n",
    "var_values = [np.percentile(returns, (1-cl)*100) for cl in confidence_levels]\n",
    "cvar_values = [np.mean(returns[returns <= var]) for var in var_values]\n",
    "\n",
    "var_df = pd.DataFrame({\n",
    "    'Confidence Level': [f\"{cl:.1%}\" for cl in confidence_levels],\n",
    "    'VaR': [f\"{v:.2%}\" for v in var_values],\n",
    "    'CVaR (Expected Shortfall)': [f\"{v:.2%}\" for v in cvar_values]\n",
    "})\n",
    "\n",
    "print(\"Value at Risk Analysis\")\n",
    "print(\"=\"*50)\n",
    "display(var_df)\n",
    "\n",
    "# Visual\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.hist(returns, bins=80, density=True, alpha=0.7, color='steelblue', edgecolor='white')\n",
    "\n",
    "colors = ['green', 'orange', 'red', 'darkred']\n",
    "for cl, var, color in zip(confidence_levels, var_values, colors):\n",
    "    ax.axvline(var, color=color, linestyle='--', linewidth=2, label=f'VaR {cl:.0%}: {var:.1%}')\n",
    "\n",
    "ax.set_xlabel('Annual Return', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Value at Risk at Multiple Confidence Levels', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Convergence Analysis\n",
    "\n",
    "Monte Carlo estimates converge as the number of simulations increases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze convergence\n",
    "sample_sizes = np.logspace(2, np.log10(len(returns)), 50).astype(int)\n",
    "\n",
    "mean_estimates = [np.mean(returns[:n]) for n in sample_sizes]\n",
    "var_estimates = [np.percentile(returns[:n], 5) for n in sample_sizes]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Mean convergence\n",
    "axes[0].plot(sample_sizes, mean_estimates, 'b-', linewidth=2)\n",
    "axes[0].axhline(np.mean(returns), color='r', linestyle='--', label=f'Final: {np.mean(returns):.4f}')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_xlabel('Number of Simulations', fontsize=12)\n",
    "axes[0].set_ylabel('Mean Return Estimate', fontsize=12)\n",
    "axes[0].set_title('Mean Estimate Convergence', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# VaR convergence\n",
    "axes[1].plot(sample_sizes, var_estimates, 'b-', linewidth=2)\n",
    "axes[1].axhline(metrics.var_95, color='r', linestyle='--', label=f'Final: {metrics.var_95:.4f}')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_xlabel('Number of Simulations', fontsize=12)\n",
    "axes[1].set_ylabel('VaR (95%) Estimate', fontsize=12)\n",
    "axes[1].set_title('VaR Estimate Convergence', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Convergence Error (SE of mean): {result.convergence_error:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Generate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate JSON report\n",
    "orch.generate_report('../output/portfolio_analysis.json', format='json')\n",
    "print(\"JSON report saved to: ../output/portfolio_analysis.json\")\n",
    "\n",
    "# Generate HTML report\n",
    "orch.generate_report('../output/portfolio_analysis.html', format='html')\n",
    "print(\"HTML report saved to: ../output/portfolio_analysis.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated the **Quantitative Systems Simulator**:\n",
    "\n",
    "### Key Features\n",
    "1. **Hybrid Python/C++ Architecture** - C++ for performance, Python for ease of use\n",
    "2. **Monte Carlo Simulation** - Correlated asset returns with Cholesky decomposition\n",
    "3. **Comprehensive Risk Metrics** - VaR, CVaR, Sharpe ratio, drawdowns\n",
    "4. **Statistical Analysis** - Normality tests, confidence intervals\n",
    "5. **Professional Visualization** - Distribution plots, path simulations, heatmaps\n",
    "\n",
    "### Portfolio Results\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Expected Return | {:.1%} |\n",
    "| Volatility | {:.1%} |\n",
    "| Sharpe Ratio | {:.2f} |\n",
    "| VaR (95%) | {:.1%} |\n",
    "| CVaR (95%) | {:.1%} |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"PORTFOLIO SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Portfolio: Tech Growth ({', '.join(portfolio_df['Symbol'].tolist())})\")\n",
    "print(f\"Simulations: {config.n_simulations:,}\")\n",
    "print(f\"Time Horizon: 1 Year ({config.time_horizon} trading days)\")\n",
    "print()\n",
    "print(f\"Expected Annual Return: {metrics.expected_return:.1%}\")\n",
    "print(f\"Volatility: {metrics.volatility:.1%}\")\n",
    "print(f\"Sharpe Ratio: {metrics.sharpe_ratio:.2f}\")\n",
    "print(f\"VaR (95%): {metrics.var_95:.1%}\")\n",
    "print(f\"CVaR (95%): {metrics.cvar_95:.1%}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
